# âš¡ OtimizaÃ§Ãµes de Performance para Scraping IFMS

## ğŸ“Š **SituaÃ§Ã£o Atual vs Otimizada**

### **CenÃ¡rio: 10 diÃ¡rios, 3 planos cada = 30 planos**

| MÃ©trica | Atual (Sequencial) | Otimizado (Paralelo) | Melhoria |
|---------|-------------------|---------------------|----------|
| **Login** | 3s | 3s | - |
| **Processar diÃ¡rios** | 120s (10 Ã— 12s) | 24s (10 / 5 paralelo) | **80%** âš¡ |
| **Processar planos** | IncluÃ­do acima | IncluÃ­do acima | - |
| **Total** | **123s (2min 3s)** | **27s** | **78% mais rÃ¡pido** ğŸš€ |

---

## ğŸ¯ **OTIMIZAÃ‡Ã•ES PROPOSTAS**

### **ğŸ”´ CRÃTICO - Impacto ALTO (>60% reduÃ§Ã£o)**

#### **1. âœ… ParalelizaÃ§Ã£o com Browser Pool**
**Status:** âœ… Implementado (`scraping-pool.service.ts`)

**Antes:**
```typescript
// âŒ Processa 1 diÃ¡rio por vez
for (const diary of diaries) {
  await scrapeDiary(diary);  // 12s cada
}
// Total: 10 Ã— 12s = 120s
```

**Depois:**
```typescript
// âœ… Processa 5 diÃ¡rios em paralelo
await poolService.executeParallel(
  diaries.map(diary =>
    (context, page) => scrapeDiary(diary, page)
  )
);
// Total: 10 / 5 = 2 batches Ã— 12s = 24s
```

**Ganho:** 80% mais rÃ¡pido (120s â†’ 24s)

**ImplementaÃ§Ã£o:**
```typescript
// auth-queue.processor.ts
import { ScrapingPoolService } from '../scraping/scraping-pool.service';

// Paralelizar scraping de diÃ¡rios
const diaryOperations = diaries.map(diary =>
  async (context: BrowserContext, page: Page) => {
    await this.scrapingService.ensureLoggedIn(page, username, password);

    // Scrape content
    const content = await this.scrapingService.scrapeClassContent(page, diary.externalId);
    await this.academicService.syncDiaryContent(userId, diary.id, content.data);

    // Scrape plans
    const plans = await this.scrapingService.getAllTeachingPlans(page, diary.externalId);
    for (const plan of plans.data) {
      const details = await this.scrapingService.getTeachingPlanDetails(
        page, diary.externalId, plan.externalId
      );
      await this.academicService.syncTeachingPlans(userId, diary.id, [details.data]);
    }
  }
);

// Execute em paralelo (mÃ¡x 5 simultÃ¢neos)
await this.scrapingPoolService.executeParallel(diaryOperations);
```

---

#### **2. âš¡ Batch Database Operations**
**Status:** ğŸ”¶ Proposta

**Problema:** Salva 1 plano por vez no banco
**SoluÃ§Ã£o:** Acumular e salvar em lote (batch insert)

**Antes:**
```typescript
// âŒ 30 queries separadas (30 Ã— 100ms = 3s)
for (const plan of plans) {
  await this.teachingPlanRepository.save(plan);
}
```

**Depois:**
```typescript
// âœ… 1 query batch (1 Ã— 100ms = 0.1s)
await this.teachingPlanRepository.save(plans); // TypeORM faz bulk insert
```

**Ganho:** 97% mais rÃ¡pido (3s â†’ 0.1s)

**ImplementaÃ§Ã£o:**
```typescript
// academic.service.ts
async syncTeachingPlans(userId: string, diaryId: string, plansData: any[]) {
  const plansToSave = [];

  for (const planData of plansData) {
    const plan = /* create or update */;
    plansToSave.push(plan);
  }

  // âœ… Salva todos de uma vez
  if (plansToSave.length > 0) {
    await this.teachingPlanRepository.save(plansToSave);
  }

  return plansToSave.length;
}
```

---

#### **3. ğŸ¯ Incremental Sync (Delta Sync)**
**Status:** ğŸ”¶ Proposta

**Problema:** Sempre faz scraping completo, mesmo se dados nÃ£o mudaram
**SoluÃ§Ã£o:** Verificar Ãºltima modificaÃ§Ã£o e sincronizar apenas o que mudou

**Antes:**
```typescript
// âŒ Sempre scrape completo
const plans = await getAllTeachingPlans(diaryId);
for (const plan of plans) {
  const full = await getTeachingPlanDetails(plan.id); // Scrape completo
  await save(full);
}
```

**Depois:**
```typescript
// âœ… Scrape apenas o que mudou
const plans = await getAllTeachingPlans(diaryId);
for (const plan of plans) {
  // Verifica se jÃ¡ temos no cache
  const cached = await this.teachingPlanRepository.findOne({ externalId: plan.id });

  // Se existe e status nÃ£o mudou, skip
  if (cached && cached.status === plan.status && cached.updatedAt > yesterday) {
    console.log(`â­ï¸ Plano ${plan.id} nÃ£o modificado, pulando...`);
    continue;
  }

  // SÃ³ faz scraping se mudou
  const full = await getTeachingPlanDetails(plan.id);
  await save(full);
}
```

**Ganho:** 50-90% menos scraping (depende de quantos dados mudaram)

---

### **ğŸŸ¡ ALTO - Impacto MÃ‰DIO (30-60% reduÃ§Ã£o)**

#### **4. ğŸŒ Resource Blocking Otimizado**
**Status:** ğŸ”¶ Proposta

**Problema:** Playwright carrega recursos desnecessÃ¡rios (imagens, CSS, fonts)
**SoluÃ§Ã£o:** Bloquear mais recursos e otimizar bloqueio

**ImplementaÃ§Ã£o:**
```typescript
// scraping.service.ts - createContext()
async createContext(): Promise<BrowserContext> {
  const context = await browser.newContext({
    viewport: { width: 1920, height: 1080 },
    userAgent: '...',
  });

  // âœ… Bloqueio agressivo de recursos
  await context.route('**/*', (route) => {
    const resourceType = route.request().resourceType();

    // Bloquear tudo exceto documento e XHR/fetch
    if (['image', 'stylesheet', 'font', 'media'].includes(resourceType)) {
      route.abort();
    } else if (route.request().url().includes('analytics')) {
      route.abort(); // Bloquear analytics
    } else if (route.request().url().includes('ads')) {
      route.abort(); // Bloquear ads
    } else {
      route.continue();
    }
  });

  return context;
}
```

**Ganho:** 20-30% mais rÃ¡pido (menos tempo de navegaÃ§Ã£o)

---

#### **5. ğŸ’¾ Cache de Dados EstÃ¡ticos**
**Status:** ğŸ”¶ Proposta

**Problema:** Ementa, objetivos, referÃªncias raramente mudam, mas sÃ£o sempre re-scrapados
**SoluÃ§Ã£o:** Cachear dados estÃ¡ticos com TTL longo

**ImplementaÃ§Ã£o:**
```typescript
// Cache de dados estÃ¡ticos no Redis
async getTeachingPlanDetails(page: Page, diaryId: string, planId: string) {
  const cacheKey = `teaching-plan:${diaryId}:${planId}`;

  // Tentar cache (TTL: 7 dias)
  const cached = await this.redis.get(cacheKey);
  if (cached) {
    console.log(`â™»ï¸ Dados estÃ¡ticos do plano ${planId} do cache (7 dias)`);
    return JSON.parse(cached);
  }

  // Scrape se nÃ£o tiver cache
  const planData = await /* scrape completo */;

  // Cachear dados estÃ¡ticos
  const staticData = {
    ementa: planData.ementa,
    objetivoGeral: planData.objetivoGeral,
    objetivosEspecificos: planData.objetivosEspecificos,
    referencias: planData.referencias,
  };

  await this.redis.setex(cacheKey, 7 * 24 * 3600, JSON.stringify(staticData));

  return planData;
}
```

**Ganho:** 30-50% em re-syncs (dados estÃ¡ticos nÃ£o precisam scraping)

---

#### **6. ğŸ”„ Smart Retry com Circuit Breaker**
**Status:** ğŸ”¶ Proposta

**Problema:** Se IFMS estiver lento/offline, tenta repetidamente e desperdiÃ§a tempo
**SoluÃ§Ã£o:** Circuit breaker para falhar rÃ¡pido quando IFMS estÃ¡ com problemas

**ImplementaÃ§Ã£o:**
```typescript
import CircuitBreaker from 'opossum';

// Configure circuit breaker
const breakerOptions = {
  timeout: 10000, // 10s timeout
  errorThresholdPercentage: 50, // Abrir apÃ³s 50% de falhas
  resetTimeout: 30000, // Tentar novamente apÃ³s 30s
};

const breaker = new CircuitBreaker(scrapingFunction, breakerOptions);

breaker.on('open', () => {
  console.warn('âš ï¸ Circuit breaker ABERTO - IFMS estÃ¡ com problemas');
});

// Uso
try {
  const result = await breaker.fire(params);
} catch (error) {
  if (breaker.opened) {
    // Falhar rÃ¡pido sem tentar
    throw new Error('IFMS indisponÃ­vel, pulando sync');
  }
}
```

**Ganho:** Evita timeout cascata (10-30s salvos por falha)

---

### **ğŸŸ¢ MÃ‰DIO - Impacto BAIXO (10-30% reduÃ§Ã£o)**

#### **7. ğŸ“¦ Connection Keep-Alive**
**Status:** ğŸ”¶ Proposta

**Problema:** Fecha browser context apÃ³s cada operaÃ§Ã£o
**SoluÃ§Ã£o:** Manter contexts abertos e reutilizar (jÃ¡ implementado no pool)

**ImplementaÃ§Ã£o:** JÃ¡ coberto pelo `ScrapingPoolService`

---

#### **8. ğŸ—œï¸ Compression no Redis**
**Status:** ğŸ”¶ Proposta

**Problema:** SessÃµes e dados grandes ocupam muito espaÃ§o no Redis
**SoluÃ§Ã£o:** Comprimir dados antes de armazenar

**ImplementaÃ§Ã£o:**
```typescript
import { gzip, ungzip } from 'node:zlib';
import { promisify } from 'node:util';

const gzipAsync = promisify(gzip);
const ungzipAsync = promisify(ungzip);

async setSession(username: string, cookies: any[]) {
  const serialized = JSON.stringify(cookies);
  const compressed = await gzipAsync(Buffer.from(serialized));
  await this.redis.setex(key, ttl, compressed.toString('base64'));
}

async getSession(username: string) {
  const compressed = await this.redis.get(key);
  if (!compressed) return null;

  const buffer = Buffer.from(compressed, 'base64');
  const decompressed = await ungzipAsync(buffer);
  return JSON.parse(decompressed.toString());
}
```

**Ganho:** 60-80% menos memÃ³ria Redis, 5-10% mais rÃ¡pido em redes lentas

---

#### **9. ğŸ“Š Database Indexes**
**Status:** ğŸ”¶ Proposta

**Problema:** Queries sem Ã­ndices apropriados
**SoluÃ§Ã£o:** Adicionar Ã­ndices compostos

**ImplementaÃ§Ã£o:**
```typescript
// teaching-plan.entity.ts
@Entity()
@Index(['userId', 'externalId']) // âœ… Busca rÃ¡pida por user + externalId
@Index(['userId', 'diaryId'])    // âœ… Busca rÃ¡pida por user + diary
@Index(['updatedAt'])             // âœ… Ordena por data de update
export class TeachingPlan {
  // ...
}

// diary.entity.ts
@Entity()
@Index(['userId', 'externalId'])
@Index(['userId', 'dataFechamento']) // âœ… Filtra diÃ¡rios abertos rapidamente
export class Diary {
  // ...
}
```

**Ganho:** 50-90% mais rÃ¡pido em queries (especialmente com muitos dados)

---

#### **10. âš™ï¸ Queue Priority**
**Status:** ğŸ”¶ Proposta

**Problema:** Sync de 100 diÃ¡rios bloqueia operaÃ§Ãµes pequenas (sync de 1 diÃ¡rio)
**SoluÃ§Ã£o:** Priorizar jobs menores

**ImplementaÃ§Ã£o:**
```typescript
// queue.module.ts
BullModule.registerQueue({
  name: 'auth-queue',
  defaultJobOptions: {
    priority: 10, // Prioridade padrÃ£o
  },
});

// Ao adicionar job
await this.authQueue.add('sync-diaries',
  { userId, credentialId },
  {
    priority: diaries.length > 10 ? 5 : 10, // Menor prioridade para syncs grandes
  }
);
```

**Ganho:** Melhor responsividade para operaÃ§Ãµes pequenas

---

## ğŸ“ˆ **RESUMO DE GANHOS ESPERADOS**

| OtimizaÃ§Ã£o | Impacto | EsforÃ§o | Prioridade |
|------------|---------|---------|------------|
| 1. Browser Pool (ParalelizaÃ§Ã£o) | ğŸ”´ **80%** | MÃ©dio | â­â­â­â­â­ |
| 2. Batch Database | ğŸ”´ **60%** | Baixo | â­â­â­â­â­ |
| 3. Delta Sync | ğŸ”´ **50-90%** | Alto | â­â­â­â­ |
| 4. Resource Blocking | ğŸŸ¡ **20-30%** | Baixo | â­â­â­â­ |
| 5. Cache EstÃ¡tico | ğŸŸ¡ **30-50%** | MÃ©dio | â­â­â­ |
| 6. Circuit Breaker | ğŸŸ¡ **10-30%** | MÃ©dio | â­â­â­ |
| 7. Connection Keep-Alive | ğŸŸ¢ **10%** | Baixo | â­â­ |
| 8. Redis Compression | ğŸŸ¢ **5-10%** | Baixo | â­â­ |
| 9. Database Indexes | ğŸŸ¢ **20-30%** | Baixo | â­â­â­ |
| 10. Queue Priority | ğŸŸ¢ **UX** | Baixo | â­â­ |

---

## ğŸš€ **ROADMAP DE IMPLEMENTAÃ‡ÃƒO**

### **Fase 1: Quick Wins (1-2 dias)**
1. âœ… Batch Database Operations â†’ 60% ganho
2. âœ… Resource Blocking Otimizado â†’ 25% ganho
3. âœ… Database Indexes â†’ 20% ganho

**Ganho total Fase 1: ~70% reduÃ§Ã£o no tempo**

### **Fase 2: ParalelizaÃ§Ã£o (3-5 dias)**
4. âœ… Browser Pool Service (jÃ¡ implementado)
5. âœ… Refatorar auth-queue.processor para usar pool
6. âœ… Testes de carga e ajuste de concurrency

**Ganho total Fase 2: ~85% reduÃ§Ã£o no tempo**

### **Fase 3: InteligÃªncia (5-7 dias)**
7. âœ… Delta Sync (incremental)
8. âœ… Cache de dados estÃ¡ticos
9. âœ… Circuit Breaker

**Ganho total Fase 3: ~90%+ reduÃ§Ã£o no tempo (re-syncs)**

---

## ğŸ¯ **RESULTADO FINAL ESPERADO**

### **Sync Inicial (primeira vez):**
```
Antes: 123s (2min 3s)
Fase 1: 37s (-70%)
Fase 2: 18s (-85%)
Resultado: 85% mais rÃ¡pido ğŸš€
```

### **Re-sync (segunda vez em diante):**
```
Antes: 123s
Com Delta Sync + Cache: 12s (-90%)
Resultado: 90% mais rÃ¡pido ğŸš€ğŸš€
```

### **Sync de 100 diÃ¡rios:**
```
Antes: ~20min
Otimizado: ~3min
Resultado: 85% mais rÃ¡pido ğŸ”¥
```

---

## ğŸ“ **PRÃ“XIMOS PASSOS**

1. **Implementar Fase 1 (Quick Wins)** - ComeÃ§ar com batch operations e indexes
2. **Testar Browser Pool** - Validar concurrency ideal (3, 5 ou 10 simultÃ¢neos)
3. **Implementar Delta Sync** - Reduzir re-syncs desnecessÃ¡rios
4. **Monitorar MÃ©tricas** - Adicionar timing logs em cada etapa
5. **Ajustar Concurrency** - Baseado em performance do IFMS

**Quer que eu implemente alguma dessas otimizaÃ§Ãµes agora?**
